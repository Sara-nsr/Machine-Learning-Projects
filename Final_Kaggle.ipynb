{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAtHC3nCMvz"
      },
      "source": [
        "**The submission consists of 3 different files:**\r\n",
        "\r\n",
        "\r\n",
        "1.   Image training file (VGG)\r\n",
        "2.   Noisy text training file (MLP)\r\n",
        "3.   Final file (merging VGG and MLP with features (gender,basecolour,usage, and season) and a final training)\r\n",
        "\r\n",
        "**Approach:**\r\n",
        "\r\n",
        "The approach to tackle this ecommerce trainign was as follows: \r\n",
        "\r\n",
        "\r\n",
        "First I trained the model using images only and got a 27 probability vector for each data set. \r\n",
        "Then I trained another model using the noisy text description and again got a 27 probability vector for each data set. \r\n",
        "At the final file, I trained the model using the information gaiend by the previous two models mentioned and I concatenated those two 27 size vectors with each data set features after one hot encoding (vector of size 5+46+4+7=62). I considered this new vector of size 116 as the entry to the final model. \r\n",
        "\r\n",
        "**Run Guide Details:**\r\n",
        "\r\n",
        "\r\n",
        "To run this code first you need to run two other models named **Final Text_Classifying Kaggle** and **Final VGG Kaggle** in that code there is a save command that save all the information of the training models into the directory. After this step you need to save those files to a file into your google drive (drag and dropping works too). After running the \"drive.mount\" command you have to give access to your drive by copying a link and there you have the information of previous trained models needed to run this final trianing model.\r\n",
        "\r\n",
        "\r\n",
        "**Few Points:**\r\n",
        "\r\n",
        "I left the intermediate running commands as comment so it helps you understand the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRPVSpsqOQkl"
      },
      "source": [
        "### **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPGPSRWTmYG8",
        "outputId": "f0ff37ee-6da4-429a-9c0d-62a187b65511"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras as keras\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skx8LBS3A0qL"
      },
      "source": [
        "### **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "wNH8NN-RCJes",
        "outputId": "efe339db-7434-4669-a328-6a3fec2b73f6"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install --upgrade kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c uw-cs480-fall20\n",
        "!ls\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('uw-cs480-fall20.zip', 'r')\n",
        "zip_ref.extractall('files')\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/33/365c0d13f07a2a54744d027fe20b60dacdfdfb33bc04746db6ad0b79340b/kaggle-1.5.10.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.10-cp36-none-any.whl size=73269 sha256=1fca84b936fa6dad7fe52fea31a968e3e6cb0a33fbdbf87cf6b7ecf7b487ac55\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.9\n",
            "    Uninstalling kaggle-1.5.9:\n",
            "      Successfully uninstalled kaggle-1.5.9\n",
            "Successfully installed kaggle-1.5.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f789579-537e-4e14-a151-c2be88a61f11\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f789579-537e-4e14-a151-c2be88a61f11\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading uw-cs480-fall20.zip to /content\n",
            " 88% 75.0M/85.6M [00:00<00:00, 86.5MB/s]\n",
            "100% 85.6M/85.6M [00:00<00:00, 123MB/s] \n",
            "drive  kaggle.json  sample_data  uw-cs480-fall20.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGnSEbvrl2EP"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/files/train.csv',dtype=str)\n",
        "test = pd.read_csv('/content/files/test.csv',dtype=str)\n",
        "\n",
        "def Addjpg(fn):\n",
        "    return fn+\".jpg\"\n",
        "\n",
        "train[\"id\"]=train[\"id\"].apply(Addjpg)\n",
        "test[\"id\"]=test[\"id\"].apply(Addjpg)   \n",
        "\n",
        "train_folder = '/content/files/suffled-images/shuffled-images'\n",
        "test_folder = '/content/files/suffled-images/shuffled-images'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qycw-9qVBzQw"
      },
      "source": [
        "Converting features to Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxVD9nodF21u"
      },
      "source": [
        "def feature2Num (train,cat):\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  ax=train[cat]\n",
        "  ax2=pd.Categorical(ax)\n",
        "  le.fit(ax2)\n",
        "  ax3 = le.transform(ax2)\n",
        "  return pd.get_dummies(ax3).to_numpy()\n",
        "\n",
        "gender = feature2Num(train,\"gender\")\n",
        "\n",
        "# print(gender.shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EzqNmqCGreK",
        "outputId": "234f1ee5-538e-4da1-96e6-acb74706a8d9"
      },
      "source": [
        "gender = feature2Num(train,\"gender\")\n",
        "baseColour = feature2Num(train,\"baseColour\")\n",
        "season = feature2Num(train,\"season\")\n",
        "usage = feature2Num(train,\"usage\")\n",
        "feature_train = np.concatenate((gender, baseColour, season, usage), axis=1)\n",
        "feature_train_lable = feature2Num(train,\"category\")\n",
        "print(feature_train.shape)\n",
        "\n",
        "gender = feature2Num(test,\"gender\")\n",
        "baseColour = feature2Num(test,\"baseColour\")\n",
        "season = feature2Num(test,\"season\")\n",
        "usage = feature2Num(test,\"usage\")\n",
        "feature_test = np.concatenate((gender, baseColour, season, usage), axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21627, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJlE_SuREvvI"
      },
      "source": [
        "### **Loading the VGG16 Model training information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fgO8A9G1OCa"
      },
      "source": [
        "model2 = keras.models.load_model('/content/drive/MyDrive/my_model_92.h2')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_FKKPp4GkfD"
      },
      "source": [
        "VGG16 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eZRKvJw1O7X",
        "outputId": "6aa6c049-908e-4f2a-8519-4c17f6cba4d2"
      },
      "source": [
        "# Define data generator\n",
        "train_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "X_train_img = train_gen.flow_from_dataframe(dataframe = train, \n",
        "directory = train_folder, x_col = 'id', \n",
        "y_col = 'category', subset=\"training\", seed = 42,\n",
        "batch_size = 100, shuffle = False, \n",
        "class_mode=\"categorical\",target_size = (80, 60))\n",
        "\n",
        "X_test_img = test_gen.flow_from_dataframe(dataframe = test, \n",
        "directory = test_folder, x_col = 'id', \n",
        "y_col = None,\n",
        "batch_size = 100, shuffle = False, \n",
        "class_mode=None,target_size = (80, 60))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21627 validated image filenames belonging to 27 classes.\n",
            "Found 21628 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ioePXk-IwR0"
      },
      "source": [
        "Getting the probability output of VGG Model for both train and test\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s5-_Kd7028v",
        "outputId": "df23efef-628b-454e-9db8-552fb2c4c45d"
      },
      "source": [
        "vgg_out_train = model2.predict_proba(X_train_img,verbose=1)\n",
        "vgg_out_test = model2.predict_proba(X_test_img,verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-097058872837>:1: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n",
            "217/217 [==============================] - 9s 42ms/step\n",
            "217/217 [==============================] - 9s 42ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf0Ce2JcJBL3"
      },
      "source": [
        "### **Loading the Noisy Text Model training information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6q0Nd7UbwWV"
      },
      "source": [
        "model3 = keras.models.load_model('/content/drive/MyDrive/MLP_89.h5')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcQtMr1JIIU"
      },
      "source": [
        "Noisy Text Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP7nJEUucNDu"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "Text_train = train['noisyTextDescription'].values\n",
        "labels = train['category'].values\n",
        "text_test = test['noisyTextDescription'].values\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(Text_train)\n",
        "tokenizer.fit_on_texts(text_test)\n",
        "\n",
        "Text_train = tokenizer.texts_to_sequences(Text_train)\n",
        "text_test = tokenizer.texts_to_sequences(text_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "maxlen = 30\n",
        "\n",
        "Text_train = pad_sequences(Text_train, padding='post', maxlen=maxlen)\n",
        "text_test = pad_sequences(text_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "labels = encoder.fit_transform(labels) \n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rlbHJOwJTzE"
      },
      "source": [
        "Getting the probability output of Noisy Text Model for both train and test\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvczmtqVcdjN"
      },
      "source": [
        "nlp_train = model3.predict_proba(Text_train)\n",
        "nlp_test = model3.predict_proba(text_test)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMP8TeY1dN62"
      },
      "source": [
        "# print(nlp_test.shape)\n",
        "# print(sentences_test.shape)\n",
        "# print(nlp_train.shape)\n",
        "# print(sentences.shape)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sKkQxx1iXg"
      },
      "source": [
        "X_train_conc=np.concatenate((vgg_out_train,feature_train,nlp_train), axis=1)\n",
        "X_test_conc=np.concatenate((vgg_out_test,feature_test,nlp_test),axis=1)\n",
        "\n",
        "# print(vgg_out_train.shape)\n",
        "# print(feature_train.T.shape)\n",
        "# print(vgg_out_test.shape)\n",
        "# print(feature_test.T.shape)\n",
        "\n",
        "# print(X_train_conc.shape)\n",
        "# print(X_test_conc.shape)\n",
        "# print(feature_train_lable.shape)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf_QknVT0yUT"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_conc, feature_train_lable, test_size=0.05, random_state=0)\n",
        "# y_train = pd.get_dummies(y_train).to_numpy()\n",
        "# y_val = pd.get_dummies(y_val).to_numpy()\n",
        "X_test = X_test_conc;\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "# print(y_train.shape)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H74_N16qKFS9"
      },
      "source": [
        "### **Main Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URI5aFISbmgT",
        "outputId": "309862a8-542e-40b9-a6ae-6ed4c703bc23"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(27))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=100, verbose=1)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "206/206 [==============================] - 1s 4ms/step - loss: 0.5352 - accuracy: 0.8719 - val_loss: 0.0739 - val_accuracy: 0.9871\n",
            "Epoch 2/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9816 - val_loss: 0.0510 - val_accuracy: 0.9898\n",
            "Epoch 3/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9868 - val_loss: 0.0507 - val_accuracy: 0.9898\n",
            "Epoch 4/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9882 - val_loss: 0.0514 - val_accuracy: 0.9889\n",
            "Epoch 5/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9898 - val_loss: 0.0522 - val_accuracy: 0.9880\n",
            "Epoch 6/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9912 - val_loss: 0.0427 - val_accuracy: 0.9908\n",
            "Epoch 7/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.0453 - val_accuracy: 0.9908\n",
            "Epoch 8/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9923 - val_loss: 0.0437 - val_accuracy: 0.9898\n",
            "Epoch 9/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9922 - val_loss: 0.0485 - val_accuracy: 0.9898\n",
            "Epoch 10/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.0530 - val_accuracy: 0.9880\n",
            "Epoch 11/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0474 - val_accuracy: 0.9898\n",
            "Epoch 12/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9940 - val_loss: 0.0437 - val_accuracy: 0.9898\n",
            "Epoch 13/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0570 - val_accuracy: 0.9889\n",
            "Epoch 14/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.0533 - val_accuracy: 0.9898\n",
            "Epoch 15/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9945 - val_loss: 0.0551 - val_accuracy: 0.9880\n",
            "Epoch 16/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.0634 - val_accuracy: 0.9871\n",
            "Epoch 17/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.0511 - val_accuracy: 0.9898\n",
            "Epoch 18/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 0.0573 - val_accuracy: 0.9898\n",
            "Epoch 19/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 0.0515 - val_accuracy: 0.9908\n",
            "Epoch 20/20\n",
            "206/206 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.0547 - val_accuracy: 0.9908\n",
            "Accuracy: 99.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB5YgqWyKZnG"
      },
      "source": [
        "Exporting to Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hniSUsLJaJRp",
        "outputId": "733e3cbe-a38f-4896-90cb-ffc6d9ffdddf"
      },
      "source": [
        "pred=model.predict_generator(X_test,verbose=1)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (X_train_img.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=X_test_img.filenames\n",
        "j=0\n",
        "for i in filenames:\n",
        "  filenames[j] = filenames[j].replace('.jpg','')\n",
        "  j=j+1\n",
        "# print(filenames)\n",
        "results_vgg=pd.DataFrame({\"id\":filenames,\"category\":predictions})\n",
        "results_vgg.to_csv(\"results_rmsp_vgg_hot_tex.csv\",index=False)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "676/676 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}